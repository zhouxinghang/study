server:
  port: 8080
spring:
  datasource:
    name: basic-db
    url: jdbc:mysql://zhouxinghang.com:3306/express?useUnicode=true&characterEncoding=utf8&zeroDateTimeBehavior=convertToNull
    username: root
    password: 123456
    driver-class-name: com.mysql.jdbc.Driver
    platform: mysql
    # mysql数据库的类型，druid可以识别不用加type属性，再说type属性也不是下面这个
    # type: com.alibaba.druid.pool.DruidDataSource
    # 下面为连接池的补充设置，应用到上面所有数据源中
    #目前Spring Boot中默认支持的连接池有dbcp,dbcp2, tomcat, hikari三种连接池。 我们要通过配置信息定制
    # 初始化大小，最小，最大
    initialSize: 1
    minIdle: 3
    maxActive: 20
    maxWait: 60000
    # 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒
    timeBetweenEvictionRunsMillis: 60000
    # 配置一个连接在池中最小生存的时间，单位是毫秒
    minEvictableIdleTimeMillis: 30000
    validationQuery: select 'x'
    testWhileIdle: true
    testOnBorrow: false
    testOnReturn: false
    # 打开PSCache，并且指定每个连接上PSCache的大小
    poolPreparedStatements: true
    maxPoolPreparedStatementPerConnectionSize: 20
    # 配置监控统计拦截的filters，去掉后监控界面sql无法统计，'wall'用于防火墙
    filters: stat,wall,slf4j
    # 通过connectProperties属性来打开mergeSql功能；慢SQL记录
    connectionProperties: druid.stat.mergeSql=true;druid.stat.slowSqlMillis=5000
    # 合并多个DruidDataSource的监控数据
    #useGlobalDataSourceStat: true
  jpa:
    show-sql: true
    properties:
      hibernate:
        hbm2ddl:
          auto: create

  #kafka相关配置
  kafka:
    bootstrap-servers: localhost:9092
    #key-value序列化反序列化
    consumer:
      group-id: 0
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
    producer:
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
      batch-size: 65536
      buffer-memory: 524288
  # No Spring Session store is configured
  session:
    store-type: none



test:
  name: zhouxinghang